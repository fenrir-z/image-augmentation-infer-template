import argparse
import json
import os
import sys


def _parse_args(args: list) -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    parser.add_argument("--rec-path", required=True, type=str)
    parser.add_argument("--manifest", required=True, type=str)
    parser.add_argument("--work-dir", required=True, type=str)
    return parser.parse_args(args)


def _run_infer(rec_path: str, manifest: dict, work_dir: str) -> str:
    """
    Code template for your own inference code, write your own code here
    Args:
        rec_path (str): path to rec file of images, generated by `MXIndexedRecordIO`
        manifest (dict): get your `model_path`, `model_config_path` and other associated task configurations
        work_dir (str): save your result jsonl file here
    Returns:
        path to your result josnl file
    Exception:
        Feel free to raise any exceptions
    """
    # TIP: use print or log to write infos to stdout
    print(f"rec_path: {rec_path}")
    print(f"manifest: {manifest}")
    print(f"work_dir: {work_dir}")

    # TIP: read model binary and config path from manifest
    model_path = manifest["model_path"]
    model_config_path = manifest["model_config_path"]

    # TIP: read images from rec_path
    # idx_path = os.path.splitext(rec_path)[0] + ".idx"
    # reader = mx.recordio.MXIndexedRecordIO(idx_path, rec_path, "r")
    # image_binaries_array = []
    # for rec_key in reader.keys():
    #     image_binaries_array.append(np.frombuffer(mx.recordio.unpack(reader.read_idx(rec_key))[1], dtype=np.uint8).tobytes())
    # reader.close()

    # write your own pred code here, this is a sample
    gt_path = os.path.splitext(rec_path)[0] + ".json"
    with open(gt_path, "r") as f:
        coco_gt = json.load(f)
    coco_preds = []
    for img in coco_gt["images"]:
        coco_preds.append(
            {
                "id": len(coco_preds),
                "image_id": img["id"],
                "category_id": 1,  # if detection
                "bbox": [0, 0, 100, 100],  # if detection
                "text": "A88888",  # if license plate
                "score": 0.9,
            }
        )

    # TIP: write result
    # save your prediction result to jsonl file
    pred_path = os.path.join(work_dir, "pred.jsonl")
    with open(pred_path, "w") as f:
        for p in coco_preds:
            f.write(json.dumps(p) + "\n")

    return pred_path


if __name__ == "__main__":
    args = _parse_args(sys.argv[1:])
    pred_path = _run_infer(
        rec_path=args.rec_path,
        manifest=json.loads(args.manifest),
        work_dir=args.work_dir,
    )

    # make kubeflow output
    os.makedirs("/tmp/outputs/Output/")
    with open("/tmp/outputs/Output/data", "w") as f:
        f.write(pred_path)
